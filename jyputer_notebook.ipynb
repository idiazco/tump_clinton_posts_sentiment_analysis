{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10d98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the libraries we are going to neek\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1646639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar VADER (solo primera vez)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93215cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data\n",
    "df = pd.read_excel(\"data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b6da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create the stopword list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# we are going to tonekize each sentence \n",
    "def tokenize_message(text):\n",
    "    return [word for word in word_tokenize(str(text).lower()) \n",
    "            if word not in stop_words]\n",
    "\n",
    "df['tokens'] = df['Message'].apply(tokenize_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c5e8f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicar TextBlob a cada mensaje individualmente\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNaiveBayesAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentiment\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Ver resultados\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\iredi\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iredi\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iredi\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\iredi\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\iredi\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicar TextBlob a cada mensaje individualmente\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mTextBlob\u001b[49m(\u001b[38;5;28mstr\u001b[39m(x), analyzer\u001b[38;5;241m=\u001b[39mNaiveBayesAnalyzer())\u001b[38;5;241m.\u001b[39msentiment\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Ver resultados\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_analysis\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "# Aplicar TextBlob a cada mensaje individualmente\n",
    "df['sentiment_analysis'] = df['Message'].apply(\n",
    "    lambda x: TextBlob(str(x), analyzer=NaiveBayesAnalyzer()).sentiment\n",
    ")\n",
    "\n",
    "# Ver resultados\n",
    "print(df[['Message', 'sentiment_analysis']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122f65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Analizando con VADER...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 998/998 [00:00<00:00, 3620.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# initiallize\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# definning the classification: according to polarity scores, we will have positive, negative, or neutral score\n",
    "# we also have the compound score, which is a weighted composite of the three (not a simple average)\n",
    "def analyze_vader_batch(messages):\n",
    "    results = []\n",
    "    for msg in tqdm(messages, desc=\"Procesando\"):\n",
    "        scores = sia.polarity_scores(str(msg))\n",
    "        results.append({\n",
    "            'vader_compound': scores['compound'],\n",
    "            'vader_positive': scores['pos'],\n",
    "            'vader_negative': scores['neg'],\n",
    "            'vader_neutral': scores['neu']\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# we will have the polarity scores in four extra columns, which are the vader_results\n",
    "vader_results = analyze_vader_batch(df['Message'].tolist())\n",
    "df = pd.concat([df, vader_results], axis=1)\n",
    "\n",
    "# and according to the compound score, we will have the final classification\n",
    "# Using standard VADER thresholds: â‰¥0.05 positive, â‰¤-0.05 negative, else neutral\n",
    "df['sentiment_label'] = df['vader_compound'].apply(\n",
    "    lambda x: 'POSITIVO' if x >= 0.05 else 'NEGATIVO' if x <= -0.05 else 'NEUTRAL'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d3c2cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Post ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Post URL</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>vader_positive</th>\n",
       "      <th>vader_negative</th>\n",
       "      <th>vader_neutral</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>2016-07-15 13:00:01</td>\n",
       "      <td>889307941125736_1189151237808070</td>\n",
       "      <td>If you like Donald Trump, youâ€™re going to love...</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>https://facebook.com/889307941125736/posts/118...</td>\n",
       "      <td>[like, donald, trump, ,, â€™, going, love, choic...</td>\n",
       "      <td>0.7717</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.642</td>\n",
       "      <td>POSITIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>2016-07-15 11:00:28</td>\n",
       "      <td>889307941125736_1189077061148821</td>\n",
       "      <td>This election isnâ€™t just a choice between two ...</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>https://facebook.com/889307941125736/posts/118...</td>\n",
       "      <td>[election, â€™, choice, two, partiesâ€”it, â€™, deci...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>2016-07-15 10:30:12</td>\n",
       "      <td>889307941125736_1189051547818039</td>\n",
       "      <td>If you ever had any doubts about Donald J. Tru...</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>https://facebook.com/889307941125736/posts/118...</td>\n",
       "      <td>[ever, doubts, donald, j., trump, sticking, di...</td>\n",
       "      <td>-0.6486</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.813</td>\n",
       "      <td>NEGATIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>2016-07-15 10:01:34</td>\n",
       "      <td>889307941125736_1189019197821274</td>\n",
       "      <td>It's official: Donald J. Trump just chose Indi...</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>https://facebook.com/889307941125736/posts/118...</td>\n",
       "      <td>['s, official, :, donald, j., trump, chose, in...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinton</td>\n",
       "      <td>2016-07-15 09:40:27</td>\n",
       "      <td>889307941125736_1189009067822287</td>\n",
       "      <td>Thank you, Virginia and Senator Tim Kaine.</td>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>https://facebook.com/889307941125736/posts/118...</td>\n",
       "      <td>[thank, ,, virginia, senator, tim, kaine, .]</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.706</td>\n",
       "      <td>POSITIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2016-05-02 06:00:11</td>\n",
       "      <td>153080620724_10156993424940725</td>\n",
       "      <td>I will easily beat Crooked Hillary Clinton in ...</td>\n",
       "      <td>2016-05-02</td>\n",
       "      <td>https://facebook.com/153080620724/posts/101569...</td>\n",
       "      <td>[easily, beat, crooked, hillary, clinton, gene...</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.731</td>\n",
       "      <td>POSITIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2016-05-01 17:53:37</td>\n",
       "      <td>153080620724_10156992889270725</td>\n",
       "      <td>I love you Fort Wayne, Indiana! What a great e...</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>https://facebook.com/153080620724/posts/101569...</td>\n",
       "      <td>[love, fort, wayne, ,, indiana, !, great, even...</td>\n",
       "      <td>0.9203</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.646</td>\n",
       "      <td>POSITIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2016-05-01 13:30:59</td>\n",
       "      <td>153080620724_10156991970810725</td>\n",
       "      <td>WOW! I am departing Terre Haute, Indiana now. ...</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>https://facebook.com/153080620724/posts/101569...</td>\n",
       "      <td>[wow, !, departing, terre, haute, ,, indiana, ...</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>POSITIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2016-05-01 11:51:35</td>\n",
       "      <td>153080620724_10156991664675725</td>\n",
       "      <td>Great new poll out of Indiana! THANK YOU! I am...</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>https://facebook.com/153080620724/posts/101569...</td>\n",
       "      <td>[great, new, poll, indiana, !, thank, !, terre...</td>\n",
       "      <td>0.9614</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.593</td>\n",
       "      <td>POSITIVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Trump</td>\n",
       "      <td>2016-05-01 07:12:05</td>\n",
       "      <td>153080620724_10156990785925725</td>\n",
       "      <td>When our POTUS or my soon to be opponent (Croo...</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>https://facebook.com/153080620724/posts/101569...</td>\n",
       "      <td>[potus, soon, opponent, (, crooked, hillary, )...</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.743</td>\n",
       "      <td>NEGATIVO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Candidate            DateTime                           Post ID  \\\n",
       "0     Clinton 2016-07-15 13:00:01  889307941125736_1189151237808070   \n",
       "1     Clinton 2016-07-15 11:00:28  889307941125736_1189077061148821   \n",
       "2     Clinton 2016-07-15 10:30:12  889307941125736_1189051547818039   \n",
       "3     Clinton 2016-07-15 10:01:34  889307941125736_1189019197821274   \n",
       "4     Clinton 2016-07-15 09:40:27  889307941125736_1189009067822287   \n",
       "..        ...                 ...                               ...   \n",
       "993     Trump 2016-05-02 06:00:11    153080620724_10156993424940725   \n",
       "994     Trump 2016-05-01 17:53:37    153080620724_10156992889270725   \n",
       "995     Trump 2016-05-01 13:30:59    153080620724_10156991970810725   \n",
       "996     Trump 2016-05-01 11:51:35    153080620724_10156991664675725   \n",
       "997     Trump 2016-05-01 07:12:05    153080620724_10156990785925725   \n",
       "\n",
       "                                               Message       Date  \\\n",
       "0    If you like Donald Trump, youâ€™re going to love... 2016-07-15   \n",
       "1    This election isnâ€™t just a choice between two ... 2016-07-15   \n",
       "2    If you ever had any doubts about Donald J. Tru... 2016-07-15   \n",
       "3    It's official: Donald J. Trump just chose Indi... 2016-07-15   \n",
       "4           Thank you, Virginia and Senator Tim Kaine. 2016-07-15   \n",
       "..                                                 ...        ...   \n",
       "993  I will easily beat Crooked Hillary Clinton in ... 2016-05-02   \n",
       "994  I love you Fort Wayne, Indiana! What a great e... 2016-05-01   \n",
       "995  WOW! I am departing Terre Haute, Indiana now. ... 2016-05-01   \n",
       "996  Great new poll out of Indiana! THANK YOU! I am... 2016-05-01   \n",
       "997  When our POTUS or my soon to be opponent (Croo... 2016-05-01   \n",
       "\n",
       "                                              Post URL  \\\n",
       "0    https://facebook.com/889307941125736/posts/118...   \n",
       "1    https://facebook.com/889307941125736/posts/118...   \n",
       "2    https://facebook.com/889307941125736/posts/118...   \n",
       "3    https://facebook.com/889307941125736/posts/118...   \n",
       "4    https://facebook.com/889307941125736/posts/118...   \n",
       "..                                                 ...   \n",
       "993  https://facebook.com/153080620724/posts/101569...   \n",
       "994  https://facebook.com/153080620724/posts/101569...   \n",
       "995  https://facebook.com/153080620724/posts/101569...   \n",
       "996  https://facebook.com/153080620724/posts/101569...   \n",
       "997  https://facebook.com/153080620724/posts/101569...   \n",
       "\n",
       "                                                tokens  vader_compound  \\\n",
       "0    [like, donald, trump, ,, â€™, going, love, choic...          0.7717   \n",
       "1    [election, â€™, choice, two, partiesâ€”it, â€™, deci...          0.0000   \n",
       "2    [ever, doubts, donald, j., trump, sticking, di...         -0.6486   \n",
       "3    ['s, official, :, donald, j., trump, chose, in...          0.0000   \n",
       "4         [thank, ,, virginia, senator, tim, kaine, .]          0.3612   \n",
       "..                                                 ...             ...   \n",
       "993  [easily, beat, crooked, hillary, clinton, gene...          0.8087   \n",
       "994  [love, fort, wayne, ,, indiana, !, great, even...          0.9203   \n",
       "995  [wow, !, departing, terre, haute, ,, indiana, ...          0.9631   \n",
       "996  [great, new, poll, indiana, !, thank, !, terre...          0.9614   \n",
       "997  [potus, soon, opponent, (, crooked, hillary, )...         -0.4125   \n",
       "\n",
       "     vader_positive  vader_negative  vader_neutral sentiment_label  \n",
       "0             0.358           0.000          0.642        POSITIVO  \n",
       "1             0.000           0.000          1.000         NEUTRAL  \n",
       "2             0.000           0.187          0.813        NEGATIVO  \n",
       "3             0.000           0.000          1.000         NEUTRAL  \n",
       "4             0.294           0.000          0.706        POSITIVO  \n",
       "..              ...             ...            ...             ...  \n",
       "993           0.213           0.056          0.731        POSITIVO  \n",
       "994           0.296           0.059          0.646        POSITIVO  \n",
       "995           0.386           0.000          0.614        POSITIVO  \n",
       "996           0.407           0.000          0.593        POSITIVO  \n",
       "997           0.100           0.157          0.743        NEGATIVO  \n",
       "\n",
       "[998 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save it in another Excel file\n",
    "df.to_excel('analisis_sentimientos_completo.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
